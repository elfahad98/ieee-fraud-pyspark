# D√©tection de fraude bancaire ‚Äî Machine Learning avec (PySpark)

> Pipeline de classification **PySpark / MLlib** sur **IEEE-CIS (Kaggle)** :  
> ~590 k transactions, **‚âà 400 variables disponibles** apr√®s fusion (`transaction` + `identity`),  
> **3,5 %** de fraudes (d√©s√©quilibre marqu√©), variables largement anonymis√©es.

<!-- Optionnel : ajoute la capture si tu la poses dans docs/ -->
<!-- ![Dashboard Superset (aper√ßu)](docs/superset_hero.png) -->

---

##  Objectif & p√©rim√®tre

Construire un pipeline **distribu√©** et **reproductible** pour pr√©dire `isFraud` sur un jeu de donn√©es
large et h√©t√©rog√®ne, **sans analyser exhaustivement chaque variable** : l‚ÄôEDA sert √† **cibler un
sous-ensemble de variables r√©ellement informatives**, puis on optimise le mod√®le (s√©lection,
tuning **manuel** et **calibration du seuil**) en tenant compte du **d√©s√©quilibre (~3,5 %)**.

---

##  M√©thodologie (6 √©tapes)

1) **Pr√©traitement initial**  
   - Chargement `train_transaction` et `train_identity`  
   - **Fusion** (LEFT JOIN) sur `TransactionID`  
   - **EDA ‚Äúbrute‚Äù** : structure, typage, taux de fraude, d√©tection d‚Äôanomalies simples

2) **Nettoyage cibl√©**  
   - Suppression des colonnes peu informatives (beaucoup de NaN / constantes)  
   - Cr√©ation d‚Äôindicateurs **`has_X`** pour colonnes tr√®s incompl√®tes  
   - **Imputation** : m√©diane (num√©riques), `"unknown"` (cat√©gorielles)

3) **Analyse exploratoire avanc√©e (EDA)**  
   - Relations avec `isFraud` (ex. `TransactionAmt`, `D1`, `C1`, `ProductCD`, `card4`, `card6`, domaines email‚Ä¶)  
   - Recherche de **patterns**, effets de seuil, corr√©lations, **groupes √† risque**  
   - L‚ÄôEDA **guide** la suite : on **cible** des familles/variables utiles (on ne balaie **pas** ‚Äúles 400‚Äù une par une)

4) **Feature Engineering (FE)**  
   - D√©riv√©es & ratios : `log1p_TransactionAmt`, `C1/D1`, `day`, `is_weekend`‚Ä¶  
   - **Flags m√©tier** : `is_product_C`, `card4_card6`, `is_high_amount`, `is_recent_activity`, `is_recent_intense`, etc.  
   - **Encodage** :  
     - faible cardinalit√© ‚Üí `StringIndexer` + `OneHotEncoder`  
     - cardinalit√© √©lev√©e (emails) ‚Üí **frequency encoding**  
   - **Assemblage** : `VectorAssembler` (+ `StandardScaler` si pertinent)

5) **Mod√©lisation & d√©s√©quilibre**  
   - **Split** 80/20 (seed fixe)  
   - **Pond√©ration** des classes via `weightCol`  
   - **Benchmark** : Logistic Regression (baseline), Random Forest, **GBT**

6) **Optimisation & s√©lection**  
   - **S√©lection** de variables (importances GBT : globales / par familles / `Vxx` + filtre simple)  
   - **Tuning manuel** cibl√© (ex. `maxDepth`, `maxIter`) sur sous-√©chantillon  
   - **Calibration du seuil** pour optimiser le compromis pr√©cision/rappel

---

##  Stack

- **Spark / PySpark (MLlib)** : pr√©paration, pipeline, mod√®les  
- **Python** : pandas, numpy, **scipy** (tests statistiques : œá¬≤, etc.), matplotlib/seaborn  
- **Superset** : visualisation EDA & suivi des indicateurs (**pas** en temps r√©el)  
- *(Optionnel)* **SHAP** sur un √©chantillon Pandas (proxy sklearn) pour interpr√©tabilit√©

---

##  Donn√©es

Comp√©tition **IEEE-CIS Fraud Detection** (Kaggle).  
Les fichiers **ne sont pas versionn√©s** (licence) :
- `train_transaction.csv`
- `train_identity.csv`

> Placez les donn√©es dans `./data/` (r√©pertoire ignor√© par git).

---

## R√©sultats (validation)

| Mod√®le            | ROC-AUC | PR-AUC | F1    | Pr√©cision | Rappel |
|-------------------|:------:|:-----:|:-----:|:--------:|:------:|
| **GBT (optimis√©)**| **0.954** | **0.74** | **0.692** | **0.78** | **0.64** |

**Mod√®le retenu** : `GBTClassifier` (**maxDepth=10**, **maxIter=100**, **seuil=0.845**).  
R√©glages efficaces : **features cibl√©es**, **s√©lection**, **tuning**, **calibration du seuil**.


---

## Visualisations cl√©s

| Figure | Commentaire rapide |
|:--|:--|
| ![PR curves](screenshots/optirapp.png) | **Pr√©cision‚ÄìRappel (val.)** : **PR-AUC ‚âà 0,737** (*pr√©valence ‚âà 3,5 %*) ‚Äî bonne s√©paration malgr√© le fort d√©s√©quilibre. |
| ![Threshold](screenshots/Validation__GBT__threshold_curves.png) | **Courbes Precision/Recall/F1 vs seuil** : pic **F1=0.692** au **seuil=0.845** ‚Üí compromis adopt√©. |
| ![Confusion](screenshots/Validation__GBT__confusion_matrix_t0.84.png) | **Matrice (val., t‚âà0.845)** : **TP=2 646**, **FP=743**, **FN=1 610**, **TN=113 109** ‚Üí erreurs surtout c√¥t√© rappel. |
| ![Gain](screenshots/Validation__GBT__cumulative_gain.png) | **Gain cumulatif** : en priorisant ~les meilleurs scores, une petite part de la population capte la majorit√© des fraudes. |
| ![Calibration](screenshots/Validation__GBT__calibration_curve.png) | **Calibration** : l√©g√®re **sur-confiance** en milieu de gamme (courbe sous la diagonale) ‚Üí √† corriger si la proba est consomm√©e telle quelle. |
| ![SHAP](screenshots/shap.png) | **Interpr√©tabilit√© (SHAP, √©chantillon)** : `TransactionAmt`, `card1`, `log1p_D15`, `C13`, `V257` ressortent clairement. |


### Pistes d‚Äôam√©lioration
- **Calibration** (isotonic / Platt) sur un set d√©di√©, puis r√©√©val sur un **hold-out**.
- **Validation temporelle** (split par date) pour mieux g√©rer la d√©rive.
- **Features** robustes (fen√™tres temporelles, ratios stables, encodages fr√©quence).
- **Suivi prod** : PR-AUC, PR@k, drift des features/labels, r√©-entra√Ænement p√©riodique.


---


##  Prise en main

```bash
# 0) Cloner
git clone https://github.com/elfahad98/ieee-fraud-pyspark.git
cd ieee-fraud-pyspark

# 1) Environnement (ex. venv)
python -m venv .venv
# Linux/Mac
source .venv/bin/activate
# Windows
# .venv\Scripts\activate
pip install -r requirements.txt

# 2) Donn√©es (non versionn√©es) : d√©poser dans ./data/
# data/train_transaction.csv
# data/train_identity.csv

# 3) Lancer
# - Notebook principal :
#   notebooks/fraud_detection_modeling1.ipynb
```

---

## üë§ Auteur

Projet r√©alis√© par **COMBO El-Fahad** ‚Äì Universit√© de Caen (2025).  
Contact : `el-fahad.combo@etu.unicaen.fr`

---

## üìÑ Licence

Ce projet est sous licence **MIT**. Voir le fichier `LICENSE`.
