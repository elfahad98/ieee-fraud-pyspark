# D√©tection de fraude bancaire (PySpark)

> Pipeline de classification **PySpark / MLlib** sur **IEEE-CIS (Kaggle)** :  
> ~590 k transactions, **‚âà 400 variables disponibles** apr√®s fusion (`transaction` + `identity`),  
> **3,5 %** de fraudes (d√©s√©quilibre marqu√©), variables largement anonymis√©es.

<!-- Optionnel : ajoute la capture si tu la poses dans docs/ -->
<!-- ![Dashboard Superset (aper√ßu)](docs/superset_hero.png) -->

---

##  Objectif & p√©rim√®tre

Construire un pipeline **distribu√©** et **reproductible** pour pr√©dire `isFraud` sur un jeu de donn√©es
large et h√©t√©rog√®ne, **sans analyser exhaustivement chaque variable** : l‚ÄôEDA sert √† **cibler un
sous-ensemble de variables r√©ellement informatives**, puis on optimise le mod√®le (s√©lection,
tuning **manuel** et **calibration du seuil**) en tenant compte du **d√©s√©quilibre (~3,5 %)**.

---

##  M√©thodologie (6 √©tapes)

1) **Pr√©traitement initial**  
   - Chargement `train_transaction` et `train_identity`  
   - **Fusion** (LEFT JOIN) sur `TransactionID`  
   - **EDA ‚Äúbrute‚Äù** : structure, typage, taux de fraude, d√©tection d‚Äôanomalies simples

2) **Nettoyage cibl√©**  
   - Suppression des colonnes peu informatives (beaucoup de NaN / constantes)  
   - Cr√©ation d‚Äôindicateurs **`has_X`** pour colonnes tr√®s incompl√®tes  
   - **Imputation** : m√©diane (num√©riques), `"unknown"` (cat√©gorielles)

3) **Analyse exploratoire avanc√©e (EDA)**  
   - Relations avec `isFraud` (ex. `TransactionAmt`, `D1`, `C1`, `ProductCD`, `card4`, `card6`, domaines email‚Ä¶)  
   - Recherche de **patterns**, effets de seuil, corr√©lations, **groupes √† risque**  
   - L‚ÄôEDA **guide** la suite : on **cible** des familles/variables utiles (on ne balaie **pas** ‚Äúles 400‚Äù une par une)

4) **Feature Engineering (FE)**  
   - D√©riv√©es & ratios : `log1p_TransactionAmt`, `C1/D1`, `day`, `is_weekend`‚Ä¶  
   - **Flags m√©tier** : `is_product_C`, `card4_card6`, `is_high_amount`, `is_recent_activity`, `is_recent_intense`, etc.  
   - **Encodage** :  
     - faible cardinalit√© ‚Üí `StringIndexer` + `OneHotEncoder`  
     - cardinalit√© √©lev√©e (emails) ‚Üí **frequency encoding**  
   - **Assemblage** : `VectorAssembler` (+ `StandardScaler` si pertinent)

5) **Mod√©lisation & d√©s√©quilibre**  
   - **Split** 80/20 (seed fixe)  
   - **Pond√©ration** des classes via `weightCol`  
   - **Benchmark** : Logistic Regression (baseline), Random Forest, **GBT**

6) **Optimisation & s√©lection**  
   - **S√©lection** de variables (importances GBT : globales / par familles / `Vxx` + filtre simple)  
   - **Tuning manuel** cibl√© (ex. `maxDepth`, `maxIter`) sur sous-√©chantillon  
   - **Calibration du seuil** pour optimiser le compromis pr√©cision/rappel

---

##  Stack

- **Spark / PySpark (MLlib)** : pr√©paration, pipeline, mod√®les  
- **Python** : pandas, numpy, **scipy** (tests statistiques : œá¬≤, etc.), matplotlib/seaborn  
- **Superset** : visualisation EDA & suivi des indicateurs (**pas** en temps r√©el)  
- *(Optionnel)* **SHAP** sur un √©chantillon Pandas (proxy sklearn) pour interpr√©tabilit√©

---

##  Donn√©es

Comp√©tition **IEEE-CIS Fraud Detection** (Kaggle).  
Les fichiers **ne sont pas versionn√©s** (licence) :
- `train_transaction.csv`
- `train_identity.csv`

> Placez les donn√©es dans `./data/` (r√©pertoire ignor√© par git).

---

##  R√©sultats (validation)

| Mod√®le            | ROC-AUC | PR-AUC | F1   | Pr√©cision | Rappel |
|-------------------|:------:|:-----:|:----:|:--------:|:------:|
| **GBT (optimis√©)**| **0.954** | **0.74** | **0.69** | **0.72** | **0.67** |

**Mod√®le retenu** : `GBTClassifier` (**maxDepth = 10**, **maxIter = 100**, **seuil = 0.8**).  
Le gain vient des **features ciblant les faux positifs**, de la **s√©lection de variables**, du **tuning**
et de la **calibration du seuil**.

---

## Visualisations cl√©s

| Figure | Commentaire rapide |
|:--|:--|
| ![PR curves](screenshots/optirapp.png) | **Pr√©cision‚ÄìRappel (val.)** : courbe nettement au-dessus de 0 ‚Üí le mod√®le capte bien les fraudes malgr√© le d√©s√©quilibre (PR-AUC ‚âà **0.74**). |
| ![ROC curves](screenshots/optiROC.png) | **ROC train vs val.** : AUC train ‚âà **0.98**, val. ‚âà **0.95**. L√©ger √©cart ‚Üí un peu d‚Äôoverfit mais la g√©n√©ralisation reste solide (loin d‚Äôun mod√®le al√©atoire). |
| ![Threshold](screenshots/Validation__GBT__threshold_curves.png) | **Choix du seuil** : pic **F1 ‚âà 0.69** vers **0.84‚Äì0.85** ‚Üí √† ce seuil, **pr√©cision ~0.72**, **rappel ~0.67** (bon compromis pour limiter les faux positifs). |
| ![Confusion](screenshots/Validation__GBT__confusion_matrix_t0.84.png) | **Matrice (val., seuil 0.84)** : **TP=2 646**, **FP=743**, **FN=1 610**, **TN=113 109** ‚Üí erreurs concentr√©es c√¥t√© rappel (co√ªt FN √† surveiller). |
| ![Gain](screenshots/Validation__GBT__cumulative_gain.png) | **Gain cumulatif** : en scorant par ordre d√©croissant, une petite fraction de la population capture la majorit√© des fraudes ‚Üí tr√®s bon pour des contr√¥les cibl√©s. |
| ![SHAP](screenshots/shap.png) | **Interpr√©tabilit√© (SHAP, √©chantillon)** : influence forte de `TransactionAmt`, `card1`, `log1p_D15`, `C13`, `V257`, etc. ‚Üí coh√©rent et exploitable pour l‚Äôanalyse m√©tier. |

### Bilan rapide
- Le mod√®le **n‚Äôest pas al√©atoire** (PR-AUC **0.74**, ROC-AUC **0.95** en validation).  
- Seuil op√©rationnel retenu ‚âà **0.84‚Äì0.85** ‚Üí **F1 ~0.69**, **Precision ~0.78**, **Recall ~0.62**.  
- L√©ger **overfit** mais accept√© pour un premier jet. Calibration **perfectible**.

### Pistes d‚Äôam√©lioration
- **Calibration des probabilit√©s** si elles sont utilis√©es c√¥t√© produit : *isotonic* ou *Platt scaling* sur un jeu de calibration (puis √©valuation sur un jeu tenu-out).
- **Seuils d√©pendants du co√ªt** (matrice co√ªt FP/FN) ou **seuils par segment** (ex. canal, pays, device).
- **R√©-√©chantillonnage / pond√©ration** : ajuster `weightCol`, downsample des non-fraudes, ou entra√Ænement par mini-batches pond√©r√©s.
- **Validation temporelle** (split par date) pour mieux estimer la d√©rive et √©viter la fuite d‚Äôinfo.
- **Features** suppl√©mentaires/robustes : fen√™tres temporelles (fr√©quence d‚Äôachats), ratios, encodages fr√©quence stables.
- **Surveillance en prod** : suivi PR-AUC/PR@k, drift des features/labels, r√©-entra√Ænement p√©riodique.


---


##  Prise en main

```bash
# 0) Cloner
git clone https://github.com/elfahad98/ieee-fraud-pyspark.git
cd ieee-fraud-pyspark

# 1) Environnement (ex. venv)
python -m venv .venv
# Linux/Mac
source .venv/bin/activate
# Windows
# .venv\Scripts\activate
pip install -r requirements.txt

# 2) Donn√©es (non versionn√©es) : d√©poser dans ./data/
# data/train_transaction.csv
# data/train_identity.csv

# 3) Lancer
# - Notebook principal :
#   notebooks/fraud_detection_modeling1.ipynb
```

---

## üë§ Auteur

Projet r√©alis√© par **COMBO El-Fahad** ‚Äì Universit√© de Caen (2025).  
Contact : `el-fahad.combo@etu.unicaen.fr`

---

## üìÑ Licence

Ce projet est sous licence **MIT**. Voir le fichier `LICENSE`.
