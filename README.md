# DÃ©tection de fraude bancaire (PySpark)

> Pipeline de classification **PySpark / MLlib** sur le jeu **IEEE-CIS (Kaggle)** :  
> **590 540** transactions, **â‰ˆ 434 colonnes aprÃ¨s fusion** (`transaction` + `identity`), **3,5 %** de fraudes, variables largement **anonymisÃ©es** et identitÃ© partielle. :contentReference[oaicite:0]{index=0}

---

##  Objectif & pÃ©rimÃ¨tre
Construire un pipeline distribuÃ© et **reproductible** pour prÃ©dire `isFraud` Ã  partir dâ€™un **grand nombre de variables disponibles (~400)**, en **ciblant uniquement** un **sous-ensemble informatif** identifiÃ© par lâ€™EDA et par la **sÃ©lection de variables** (importances GBT par familles/id/`Vxx` + filtre `Vxx` > 0,01). :contentReference[oaicite:1]{index=1}  
ConcrÃ¨tement :
- **Fusion** `train_transaction` + `train_identity` (LEFT JOIN sur `TransactionID`). :contentReference[oaicite:2]{index=2}  
- **Nettoyage ciblÃ©** : retrait colonnes > 90 % NaN, crÃ©ation dâ€™indicateurs `has_X` (80â€“90 % manquants), **imputation** (mÃ©diane num, `"unknown"` cat). :contentReference[oaicite:3]{index=3}  
- **Feature engineering guidÃ© par lâ€™EDA** : dÃ©rivÃ©es (`log1p_TransactionAmt`, `C1/D1`, `day`, `is_weekend`), **flags mÃ©tier** (`is_product_C`, `is_credit_card`, `is_discover_card`, `card4_card6`, `is_recent_activity`, `is_recent_intense`, etc.). :contentReference[oaicite:4]{index=4}  
- **Encodage** : `StringIndexer` + `OneHotEncoder` (faible cardinalitÃ©), **frequency encoding** pour email-domains, assemblage `VectorAssembler`, scaling si utile. :contentReference[oaicite:5]{index=5}  
- **DÃ©sÃ©quilibre** (3,5 % fraude) gÃ©rÃ© par **pondÃ©ration des classes** (`weightCol`). :contentReference[oaicite:6]{index=6}  
- **ModÃ¨les** benchmark : Logistic Regression, Random Forest, **GBT**. :contentReference[oaicite:7]{index=7}  
- **Optimisation** : sÃ©lection de variables, **tuning** (`maxDepth`, `maxIter`) sur sous-Ã©chantillon 40 %, **calibrage du seuil** de dÃ©cision. :contentReference[oaicite:8]{index=8}

---

## âš™ï¸ Stack
- **Spark / PySpark (MLlib)** : prÃ©paration, pipeline, modÃ¨les  
- **Python** : pandas, numpy, **scipy** (tests stats : Mann-Whitney, Ï‡Â²), matplotlib/seaborn  
- **Superset** : EDA & visualisation (captures dans `docs/`)  
- *(Optionnel)* **scikit-learn** : modÃ¨le proxy pour **SHAP** (interprÃ©tabilitÃ©). :contentReference[oaicite:9]{index=9}

---

## ðŸ§± Pipeline (trÃ¨s synthÃ©tique)
1) Fusion & typage â†’ 2) Nettoyage (NaN, `has_X`, imputation) â†’  
3) EDA avancÃ©e (cible vs `TransactionAmt`, `D1`, `C1`, `ProductCD`, `card4`, `card6`, etc.) â†’ 4) FE (ratios/flags/temps) â†’  
5) Encodage & assemblage â†’ 6) Split 80/20 (seed=42), **pondÃ©ration** â†’ 7) Benchmark â†’ 8) SÃ©lection + tuning + **seuil**. :contentReference[oaicite:10]{index=10}

---

## ðŸ”¢ RÃ©sultats finaux (validation)
**ModÃ¨le retenu** : `GBTClassifier` (**maxDepth=10**, **maxIter=100**, **seuil=0.8**).  
**Validation** : **ROC-AUC = 0.9543**, **F1 = 0.6948**, **Precision = 0.7194**, **Recall = 0.6718**. :contentReference[oaicite:11]{index=11}

> Le gain vient de : **features ciblant les faux positifs**, sÃ©lection de variables, **tuning** + **calibration du seuil** (prÃ©cision ~14 % â†’ ~72 %). :contentReference[oaicite:12]{index=12}

---

## ðŸš€ Reproduire
```bash
# 0) Cloner
git clone https://github.com/elfahad98/ieee-fraud-pyspark.git
cd ieee-fraud-pyspark

# 1) Environnement (ex. venv)
python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\Scripts\activate)
pip install -r requirements.txt

# 2) DonnÃ©es (non versionnÃ©es)
# DÃ©poser depuis Kaggle :
# data/train_transaction.csv
# data/train_identity.csv

# 3) Lancer
# - Notebook principal : notebooks/fraud_detection_modeling1.ipynb
# - ou script (si fourni plus tard) : python scripts/train_gbt.py --data_dir data
